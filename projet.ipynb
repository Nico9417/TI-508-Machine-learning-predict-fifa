{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projet Machine Learning - Determine Football Player Poisition\n",
    "\n",
    "Authors:\n",
    "- Grégoire ALPEROVITCH\n",
    "- Nicolas FLANDIN\n",
    "- Maxime Chamont\n",
    "\n",
    "# Introduction\n",
    "\n",
    "All 3 of us are passionate about football, so we decided to combine our shared passion with our IT skills in this project. In fact, from a computer point of view, football players can be seen as objects with precise statistics that reflect their ability. That's how we came up with the hypothesis that these statistics could be used as factors to determine their role on the pitch. For example, a player with good shooting ability would seem to be an attacker, just as a player who could easily intercept balls would be a defender.\n",
    "\n",
    "Now that we have these observations, we can start to imagine a machine learning model that can guess a player's position as a defender, striker or midfielder. So here we have our features, which we'll abbreviate as ATT, DEF, MID. To carry out our project we have found on this <a href=\"https://www.kaggle.com/datasets/nyagami/ea-sports-fc-25-database-ratings-and-stats?select=male_players.csv\">link</a>, a database containing all the professional football players with their statistics and their position. \n",
    "\n",
    "To help us develop this model, we will use the pandas, numpy, sklearn and matplotlib packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The package pandas will help us to manipulate the datas into dataframe, a python object for datas\n",
    "import pandas as pd\n",
    "\n",
    "file_path = \"./male_players.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, as we can see from the male_player.csv file, this database is very dense and complex, meaning that we will have to process our data before we can start tuning the model. The first step in our data processing is to remove the ‘GK’ label. We do this because players with the ‘GK’’ label have special and unique features. So our model won't be able to guess them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleansing: remove spaces around positions\n",
    "data['Position'] = data['Position'].str.strip()\n",
    "\n",
    "# Exclude goalkeepers (GK) from data \n",
    "data = data[data['Position'] != 'GK']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained earlier, each player is assigned to a position that corresponds to his position on the pitch (our label). However, we're going to simplify these positions, especially as many of these positions are virtually identical. This will create redundancy in the results, which will distort the model and reduce accuracy. To do this, we will group the identical positions into a single category. Then, Specific positions (“ST”, “CM”...) are grouped into general labels (“ATT”, “MID”, “DEF”)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position dictionary with main categories\n",
    "positions = {\n",
    "    \"ATT\": [\"LW\", \"RW\", \"ST\"],\n",
    "    \"MID\": [\"CM\", \"CDM\", \"CAM\", \"LM\", \"RM\"],\n",
    "    \"DEF\": [\"LB\", \"RB\", \"CB\"]\n",
    "}\n",
    "\n",
    "# Position mapping function\n",
    "def map_position(position):\n",
    "    for category, values in positions.items():\n",
    "        if position in values:\n",
    "            return category\n",
    "    return position  # If the position is not in the dictionary, we keep it unchanged\n",
    "\n",
    "# Applying the `map_position` function to the DataFrame's 'Position' column\n",
    "data['Position'] = data['Position'].apply(map_position)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many features in this model, but many of them are redundant. For example, a player's top speed and his normal speed are two features with a very strong correlation. So we're going to remove one of them. Redundancy has the effect of disrupting the model. At the same time, we'll remove rows with incorrect or empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features with more detailed stats than the base ones\n",
    "features = [\n",
    "    'PAC', 'SHO', 'PAS', 'DRI', 'DEF', 'PHY',               # Base stats on cards\n",
    "    'Finishing', 'Heading Accuracy', 'Positioning',        # Attacking statistics \n",
    "    'Short Passing', 'Long Passing', 'Vision',             # Midfield statistics\n",
    "    'Ball Control', 'Standing Tackle', 'Sliding Tackle',   # Defensive statistics\n",
    "    'Interceptions', 'Acceleration', 'Sprint Speed',       # Additional recommended stats\n",
    "    'Agility', 'Balance', 'Stamina', 'Strength'            # Physical and agility stats \n",
    "]\n",
    "\n",
    "# Drop rows with missing values for any of the selected features\n",
    "data = data.dropna(subset=features)\n",
    "\n",
    "# Define features and label\n",
    "X = data[features] \n",
    "y = data['Position']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, The data is standardized to ensure that all features are on a comparable scale, and is divided into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features \n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we define and prepare the machine learning models that will be used to predict player positions based on their statistics. The models chosen cover a variety of popular approaches to supervised learning(KNN, Random Forest, SVM, Softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multiple models and store them for future use\n",
    "models = {\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=51),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(kernel='linear', probability=True),\n",
    "    'Logistic Regression (Softmax)': LogisticRegression(max_iter=200, multi_class='multinomial', solver='lbfgs')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each model is trained and evaluated on the test set, displaying accuracy, a classification ratio and a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate each model\n",
    "def evaluate_models(models, X_train, X_test, y_train, y_test):\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Accuracy of {model_name}: {accuracy * 100:.2f}%\")\n",
    "        print(\"Classification report:\\n\", classification_report(y_test, y_pred))\n",
    "        print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "        print(\"\\n\" + \"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a function to test different numbers of neighbors for KNN and to display their impact on accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to determine the optimal K for KNN\n",
    "def find_best_k(X_train, y_train, X_test, y_test):\n",
    "    Ks = 100\n",
    "    mean_acc = np.zeros((Ks-1))\n",
    "\n",
    "    for n in range(1, Ks):\n",
    "        neigh = KNeighborsClassifier(n_neighbors=n).fit(X_train, y_train)\n",
    "        yhat = neigh.predict(X_test)\n",
    "        mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)\n",
    "\n",
    "    # Plot accuracy vs K\n",
    "    plt.plot(range(1, Ks), mean_acc, 'g')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Number of Neighbors (K)')\n",
    "    plt.title('Accuracy vs. Number of Neighbors (K)')\n",
    "    plt.show()\n",
    "\n",
    "    # Displays the best precision obtained and the corresponding k value.\n",
    "    print(\"The best accuracy was with\", mean_acc.max(), \"with k=\", mean_acc.argmax()+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim is to predict the position of a specific player based on his statistics and the selected model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict player's position based on their name and chosen model\n",
    "def predict_player_position(player_name, model, data, features, scaler):\n",
    "    # Case-insensitive search for player's name\n",
    "    player_data = data[data['Name'].str.contains(player_name, case=False, na=False)]\n",
    "    \n",
    "    if player_data.empty:\n",
    "        print(\"Player not found!\")\n",
    "        return\n",
    "    \n",
    "    # Extract the player's features\n",
    "    player_features = player_data[features].values\n",
    "    \n",
    "    # Normalize the player's features using the same scaler as the training data\n",
    "    player_features_scaled = scaler.transform(player_features)\n",
    "    \n",
    "    # Predict the player's position using the selected model\n",
    "    predicted_position = model.predict(player_features_scaled)\n",
    "    \n",
    "    # Extract first prediction if the result is an array\n",
    "    predicted_position = predicted_position[0] if len(predicted_position) > 0 else predicted_position\n",
    "    \n",
    "    # Simplify predicted positions to broader categories\n",
    "    if predicted_position in [\"ST\", \"LW\", \"RW\"]:\n",
    "        predicted_position = \"ATT\"\n",
    "    elif predicted_position in [\"CM\", \"CDM\", \"CAM\", \"LM\", \"RM\"]:\n",
    "        predicted_position = \"MID\"\n",
    "    elif predicted_position in [\"LB\", \"RB\", \"CB\"]:\n",
    "        predicted_position = \"DEF\"\n",
    "\n",
    "    print(f\"The predicted position for {player_name} is: {predicted_position}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
